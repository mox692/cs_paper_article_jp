# [日本語訳] ハードウェアメモリモデル -Hardware Memory Models-
> *Original Article*: https://research.swtch.com/hwmm
> 
> This article is translated by [@mox692](https://twitter.com/mox692). Please contact me if any problem.

はじめに おとぎ話の結末 昔、誰もがシングルスレッドでプログラムを書いていた頃、プログラムの実行速度を上げる最も効果的な方法の1つは、何もせずにじっとしていることでした。次世代ハードウェアや次世代コンパイラの最適化によって、プログラムは以前とまったく同じように、ただ速く動くようになるのです。このおとぎ話のような時代には、最適化が有効かどうかを簡単に判断することができました。有効なプログラムを実行したときに、最適化されていない状態と最適化されている状態の違いを、プログラマーが（スピードアップを除いて）見分けることができなければ、その最適化は有効なものだったということです。つまり、有効な最適化は、有効なプログラムの動作を変えないということです。

何年も前のある悲しい日、個々のプロセッサを高速化するためのハードウェアエンジニアの魔法の呪文が効かなくなった。そして、オペレーティングシステムは、このハードウェアの並列処理をスレッドという抽象化した形でプログラマに公開したのです。この新しい魔法の呪文、すなわちオペレーティングシステムのスレッドという形で利用できる複数のプロセッサは、ハードウェア技術者にとっては非常に都合が良かったのですが、言語設計者、コンパイラ作成者、プログラマーにとっては大きな問題を生じました。

シングルスレッド・プログラムでは目に見えない（したがって有効な）ハードウェアやコンパイラの最適化の多くが、マルチスレッド・プログラムでは目に見える変化をもたらすのだ。もし、有効な最適化が有効なプログラムの動作を変えないのであれば、これらの最適化または既存のプログラムのどちらかを無効と宣言しなければならない。どちらになるのか、どのように判断すればよいのでしょうか。

ここにC言語風の簡単なプログラム例があります。このプログラムも、これから考えるすべてのプログラムも、初期状態ではすべての変数が0に設定されています。

<p align="center">
<img width="374" alt="スクリーンショット 2022-09-09 0 22 08" src="https://user-images.githubusercontent.com/55653825/189161585-30ed9e8f-c475-4e77-a7a0-505c5770468b.png">
</p>

スレッド1とスレッド2がそれぞれ専用のプロセッサで実行され、両方が完了するまで実行された場合、このプログラムは0を表示できるでしょうか？ それは、ハードウェアに依存します。それはハードウェアにも依存するし、コンパイラにも依存する。x86マルチプロセッサで実行されるアセンブリへの直行翻訳では、常に1が出力されます。しかし、ARMやPOWERマルチプロセッサでアセンブリに直接翻訳すると、0を表示することがあります。また、基盤となるハードウェアが何であれ、標準のコンパイラ最適化によって、このプログラムは0を表示するか、無限ループに入る可能性があります。「場合による」というのはハッピーエンドではありません。プログラマーは、あるプログラムが新しいハードウェアや新しいコンパイラでも動作し続けるかどうかについて、明確な答えを必要としています。そして、ハードウェア設計者とコンパイラ開発者は、与えられたプログラムを実行するときに、ハードウェアとコンパイルされたコードがどのように正確に動作することが許されるのかについて、明確な答えが必要です。ここでの主要な問題は、メモリに格納されたデータの変更の可視性と一貫性であるため、その契約はメモリ一貫性モデルまたは単にメモリモデルと呼ばれます。元々、メモリモデルの目標は、アセンブリコードを書くプログラマに保証されるハードウェアを定義することでした。この場合、コンパイラは関与しない。25年前、JavaやC++といった高級プログラミング言語が、その言語でコードを書くプログラマに保証するものを定義したメモリモデルを書こうとする動きが出てきました。今回は、ハードウェアのメモリモデルとプログラミング言語のメモリモデルについて、それぞれ2回ずつ投稿します。この記事を書く目的は、Goのメモリモデルに加えたい潜在的な変更について議論するための背景を構築することです。しかし、Goの現状と、Goが向かいたい方向性を理解するためには、まず、他のハードウェアのメモリモデルと言語のメモリモデルの現状と、そこに到達するまでに彼らがたどった不安定な道筋を理解しなければなりません。マルチプロセッサのコンピュータのためにアセンブリ言語を書いていると仮定しましょう。正しいプログラムを書くために、プログラマはコンピュータのハードウェアからどのような保証を得る必要があるのだろうか。コンピュータ科学者は、この問いに対する良い答えを40年以上も探し求めてきた。

## 順次一貫性
Leslie Lamport氏が1979年に発表した論文「How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs」は、逐次一貫性という概念を導入したものである。

このようなコンピュータのためにマルチプロセスアルゴリズムを設計し、その正しさを証明する従来のアプローチは、次の条件が満たされていることを前提としている：あらゆる実行結果は、すべてのプロセッサの演算がある順序で実行された場合と同じであり、個々のプロセッサの演算は、そのプログラムによって指定された順序でこの順序に現れる。この条件を満たすマルチプロセッサを順次整合性と呼ぶことにする。

今日では、コンピュータのハードウェアだけでなく、プログラミング言語でも、あるプログラムの実行が、スレッド操作のある種のインターリーブによる順次実行に対応する場合に、順次一貫性を保証することが話題になっています。逐次一貫性は、通常、理想的なモデルであり、プログラマーにとって最も自然なモデルであると考えられています。このモデルでは、プログラムはページ上に表示される順番に実行され、個々のスレッドの実行は単にある順番でインターリーブされるだけで、それ以外に再配置されることはないと仮定することができます。

順次的一貫性が理想的なモデルであるべきかという疑問は当然あるかもしれませんが、それはこの記事の範囲外です。私は、1979年当時と現在とで、すべての可能なスレッドのインターリーブを考慮することが、「マルチプロセスアルゴリズムの設計と正しさを証明するための慣習的なアプローチ」であることだけを記しておきます。この40年の間、これに代わるものは何もなかった。

先に私は、このプログラムは0を表示できるかと尋ねた。

<p align="center">
<img width="387" alt="スクリーンショット 2022-09-09 0 24 08" src="https://user-images.githubusercontent.com/55653825/189162035-2dfcd7d9-169a-4f59-adf0-2319d7661897.png">
</p>


このプログラムをもう少し解析しやすくするために、ループとprintを削除し、共有変数を読み取ることで起こりうる結果について尋ねてみましょう。

すべての例は、すべての共有変数がゼロに設定された状態で開始されると仮定します。我々はハードウェアに許されることを確立しようとしているので、各スレッドはそれ自身の専用プロセッサで実行され、スレッドで起こることを並べ替えるコンパイラは存在しないと仮定します：リスト内の命令はプロセッサが実行する命令です。rNという名前は共有変数ではなくスレッドローカルレジスタを表し、実行終了時にスレッドローカルレジスタの特定の設定が可能であるかどうかを問う。

このようなサンプルプログラムの実行結果に関する質問をリトマス試験と呼ぶ。リトマス試験は、この結果が可能か不可能かという二値的な答えを持つので、あるモデルが特定の実行を許し、別のモデルが許さない場合、その2つのモデルは明らかに異なるという、メモリモデルを区別する明確な方法を提供します。残念ながら、後で見るように、あるモデルが特定のリトマス試験に対して出す答えは意外なものであることが多い。

このリトマス試験紙の実行が順次一貫している場合、可能なインターリーブが6つしかないのです。

<p align="center">
<img width="497" alt="スクリーンショット 2022-09-09 0 45 02" src="https://user-images.githubusercontent.com/55653825/189166551-e72f0c7e-f049-414d-ad07-ab5f30f49ab7.png">
</p>

r1 = 1, r2 = 0で終わるインターリーブがないため、そのような結果は許されません。つまり、順次一貫性のあるハードウェアでは、このプログラムは r1 = 1, r2 = 0 を見ることができるかというリトマス試験紙の答えは「いいえ」なのです。

順次性一貫性の良いメンタルモデルは、すべてのプロセッサが同じ共有メモリに直接接続されていて、一度に1つのスレッドから読み取りまたは書き込み要求を出すことができると想像することです。キャッシュは存在しないので、プロセッサがメモリから読み出したり、メモリに書き込んだりする必要があるたびに、そのリクエストは共有メモリに送られます。一度に1つしか使えない共有メモリは、すべてのメモリアクセスの実行順序に順次一貫性を持たせます。

<p align="center">
<img width="495" alt="スクリーンショット 2022-09-09 0 45 13" src="https://user-images.githubusercontent.com/55653825/189166598-2f830a21-97bc-43f7-9354-a5a649a11547.png">
</p>

(この投稿にある 3 つのメモリーモデルのハードウェア図は、Maranget ら、「A Tutorial Introduction to the ARM and POWER Relaxed Memory Models」から引用しています)。

この図は、順次一貫性のあるマシンのモデルであり、それを構築する唯一の方法というわけではありません。実際、メモリフェッチの結果を予測しやすくするために、複数の共有メモリモジュールとキャッシュを使用して順次一貫したマシンを構築することは可能ですが、順次一貫しているということは、そのマシンがこのモデルと区別なく動作する必要があることを意味します。もし、単に順次一貫した実行が何を意味するかを理解しようとするならば、起こりうる実装の複雑さをすべて無視して、この1つのモデルについて考えればよいのです。

残念ながら、私たちプログラマにとっては、厳密な順次一貫性を放棄することで、ハードウェアがプログラムをより速く実行できるようになるため、現代のすべてのハードウェアは順次一貫性からさまざまな形で逸脱しています。特定のハードウェアがどのように乖離しているかを正確に定義することは、非常に難しいことが分かっています。この記事では、現在広く使われているハードウェアに存在する2つのメモリモデル、x86のメモリモデルと、ARMおよびPOWERプロセッサファミリのメモリモデルを例として取り上げます。

## x86トータル・ストア・オーダー(x86-TSO)
最近のx86システムのメモリモデルは、このハードウェア図に相当する。

<p align="center">
<img width="498" alt="スクリーンショット 2022-09-09 0 45 46" src="https://user-images.githubusercontent.com/55653825/189166759-157bdff0-4f52-4c52-9ac6-dfcdc432e27e.png">
</p>

すべてのプロセッサは単一の共有メモリに接続されているが、各プロセッサはそのメモリへの書き込みをローカル書き込みキューに待機させる。プロセッサは、書き込みが共有メモリに送られる間、新しい命令の実行を継続します。あるプロセッサのメモリリードは、メインメモリを参照する前にローカルの書き込みキューを参照しますが、他のプロセッサの書き込みキューを参照することはできません。このため、あるプロセッサは他のプロセッサよりも先に自分自身の書き込みを見ることになる。しかし、これは非常に重要なことですが、すべてのプロセッサは、書き込み（ストア）が共有メモリに到達する（合計）順序について合意しており、このモデルにはTSO（Total Store Order）という名前が付けられています。書き込みが共有メモリに到達した時点で、任意のプロセッサの将来の読み取りはその書き込みを見て、その値を使用します（後の書き込み、または他のプロセッサからのバッファ付き書き込みで上書きされるまでは）。

書き込みキューは標準的な先入れ先出しのキューで、プロセッサで実行されたのと同じ順序でメモリ書き込みが共有メモリに適用される。書き込みキューによって書き込み順序が保持され、他のプロセッサが共有メモリへの書き込みをすぐに見ることができるため、先に検討したメッセージパッシング・リトマス試験は、以前と同じ結果、r1 = 1, r2 = 0 は不可能なままとなります。

<p align="center">
<img width="336" alt="スクリーンショット 2022-09-09 0 45 54" src="https://user-images.githubusercontent.com/55653825/189166791-5d1a2965-a3f1-4a07-9a62-aba045adb320.png">
</p>

書き込みキューは、スレッド 1 が y よりも先に x をメモリに書き込むことを保証し、 メモリへの書き込みの順序に関するシステム全体の合意 (total store order) は、スレッド 2 が y の新しい値を知る前に x の新しい値を知ることを保証しています。したがって、r2 = x が新しい x を見ることなく、r1 = y が新しい y を見ることは不可能です。ここで重要なのは、スレッド 1 が y の前に x を書き込むので、スレッド 2 は x への書き込みの前に y への書き込みを見てはならない、という保存順序です。

この場合、逐次一貫性とTSOモデルは一致しますが、他のリトマス試験の結果については一致しません。例えば、これは2つのモデルを区別する通常の例である。

<p align="center">
<img width="356" alt="スクリーンショット 2022-09-09 0 46 05" src="https://user-images.githubusercontent.com/55653825/189166829-6ffa89eb-bb04-40ae-8309-57f90523c843.png">
</p>

順次一貫した実行では、x = 1 か y = 1 のどちらかが最初に起こり、次に他のスレッドの読み出しがそれを観測しなければならないので、r1 = 0, r2 = 0 はあり得ません。しかし、TSO システムでは、スレッド 1 とスレッド 2 が共に書き込みのキューに入り、どちらかの書き込みがメモリに到達する前にメモリから読み込むということが起こり得ますので、両方の読み込みが 0 を見ることになります。

この例は人工的に見えるかもしれませんが、2つの同期変数を使うことは、DekkerのアルゴリズムやPetersonのアルゴリズムのようなよく知られた同期アルゴリズムや、アドホックなスキームで起こります。あるスレッドが他のスレッドからの書き込みをすべて見ていない場合、それらは壊れます。

より強いメモリ順序に依存するアルゴリズムを修正するために、非連続一貫ハードウェアは、順序を制御するために使用できるメモリバリア（またはフェンス）と呼ばれる明示的な命令を提供します。メモリバリアを追加することで、各スレッドが読み込みを開始する前に、前の書き込みをメモリにフラッシュすることを確認することができます。

<p align="center">
<img width="299" alt="スクリーンショット 2022-09-09 0 46 23" src="https://user-images.githubusercontent.com/55653825/189166889-eff4dcd3-860f-40d7-954c-57c2db5bd958.png">
</p>

バリアの追加により、r1 = 0, r2 = 0 は再び不可能となり、Dekker や Peterson のアルゴリズムが正しく機能するようになります。障壁には多くの種類があり、詳細はシステムによって異なるため、この記事の範囲外である。重要なのは、障壁が存在し、プログラマや言語の実装者に、プログラムの重要な瞬間に順次一貫した動作を強制する方法を与えるということだけです。

最後に、なぜこのモデルがtotal store orderと呼ばれているのか、その理由を説明します。このモデルでは、ローカルに書き込みキューは存在するが、読み出しパスにはキャッシュが存在しない。書き込みがメインメモリに到達すると、すべてのプロセッサはその値がそこにあることに同意するだけでなく、他のプロセッサからの書き込みと相対的にいつ到達したのかについても同意します。このリトマス試験紙を考えてみよう。

<p align="center">
<img width="388" alt="スクリーンショット 2022-09-09 0 46 33" src="https://user-images.githubusercontent.com/55653825/189166954-ce45cb99-fcf4-4d94-9a2b-21d772fb5956.png">
</p>

 スレッド 3 が x が y よりも先に変化するのを見た場合、スレッド 4 は y が x よりも先に変化するのを見ることができるでしょうか？x86やその他のTSOマシンでは、答えはノーです。メインメモリへのすべてのストア（書き込み）には合計順序があり、すべてのプロセッサはその順序に同意します。ただし、各プロセッサはメインメモリに到達する前に自分自身の書き込みについて知っているという制約があります。


## The Path to x86-TSO


x86-TSOモデルは一見きれいに見えますが、そこに至るまでの道のりは、障害や間違った方向転換に満ちていました。1990年代、最初のx86マルチプロセッサのマニュアルには、ハードウェアが提供するメモリモデルについてほとんど何も書かれていませんでした。

問題の一例として、Plan 9はx86上で動作する最初の真のマルチプロセッサOS（グローバル・カーネル・ロックなし）の1つでした。1997年にマルチプロセッサのPentium Proに移植した際、開発者は書き込みキューのリトマス試験で煮詰まった予期せぬ動作につまずきました。同期化コードの微妙な部分が、r1 = 0, r2 = 0はあり得ないと仮定していたにもかかわらず、それが起こってしまったのだ。さらに悪いことに、Intelのマニュアルはメモリモデルの詳細について曖昧なものでした。

ハードウェア設計者が期待通りのことをしてくれると信じるよりも、ロックに対して保守的になる方が良い」というメーリングリストでの提案に対して、Plan 9 の開発者の一人がこの問題をうまく説明してくれました。

確かにそうですね。マルチプロセッサでは、より緩やかな順序付けが必要になるでしょう。問題は、ハードウェア設計者が何を保守的と考えるかです。ロックされたセクションの最初と最後の両方でインターロックを強制するのは、私にはかなり保守的に見えますが、明らかに私の想像力が足りないようです。Proのマニュアルは、キャッシュとその一貫性を保つものについて非常に詳細に説明していますが、実行や読み出しの順序については何も詳しく述べようとしないようです。実は、私たちは自分たちが十分に保守的かどうかを知る術がないのです。

この議論の中で、Intelのアーキテクトがメモリモデルについて非公式に説明し、理論的にはマルチプロセッサの486やPentiumシステムでもr1 = 0, r2 = 0の結果が得られること、Pentium Proは単にパイプラインと書き込みキューが大きく、より頻繁にその挙動が露出することを指摘している。

また、Intelのアーキテクトはこうも書いている。

緩やかに言えば、システム内の任意のプロセッサから発生するイベントの順序が、他のプロセッサによって観測されるように、常に同じであることを意味する。しかし、異なるオブザーバーが2つ以上のプロセッサからのイベントのインターリーブについて意見を異にすることは許される。

将来のIntelプロセッサは、同じメモリ順序付けモデルを実装する予定です。

異なるオブザーバーが、2つ以上のプロセッサからのイベントのインターリーブについて意見を異にすることが許される」という主張は、前節でx86が「ノー」と答えることを見たにもかかわらず、IRIWリトマス試験に対する答えはx86で「イエス」と答えることができると言っているのである。どうしてそうなるのでしょうか？

その答えは、Intelプロセッサが実際にはリトマス試験で「イエス」と答えたことはなかったが、当時Intelの設計者は将来のプロセッサについて何らかの保証をすることに消極的であったからだと思われる。アーキテクチャのマニュアルには、ほとんど何の保証もない文章が存在し、それに対してプログラムを作成することは非常に困難だった。

プラン9の議論は、決して孤立した出来事ではありませんでした。Linuxカーネル開発者たちは、1999年11月下旬から彼らのメーリングリストで、インテルプロセッサの保証をめぐる同様の混乱に100通を超えるメッセージを費やした。

その後10年間、このような問題に遭遇する人が増えてきたことを受けて、インテルのアーキテクトのグループが、現在および将来のプロセッサの動作について有用な保証を書き留める作業を行った。最初の成果は、2007年8月に発表された「Intel 64 Architecture Memory Ordering White Paper」で、「ソフトウェア開発者に、メモリアクセス命令の異なるシーケンスがもたらす結果について明確に理解させる」ことを目的としている。AMDは同年末、AMD64アーキテクチャプログラマーズマニュアル改訂3.14版で同様の記述を公開した。これらの記述は、TSOよりも意図的に弱くした「total lock order + causal consistency」（TLO+CC）というモデルに基づいている。Intelのアーキテクトは公開の場で、TLO+CCは「必要なだけの強度を持つが、それ以上強くない」と述べている。特に、このモデルでは、x86プロセッサがIRIWのリトマス試験で "yes "と答える権利を留保していた。残念ながら、メモリバリアの定義は、すべての命令の後にバリアがある場合でも、順次一貫したメモリセマンティクスを再確立するのに十分な強さではありませんでした。さらに悪いことに、研究者は実際のIntel x86ハードウェアがTLO+CCモデルに違反していることを確認しました。例えば

<p align="center">
<img width="376" alt="スクリーンショット 2022-09-09 0 47 45" src="https://user-images.githubusercontent.com/55653825/189167195-076335bb-9f03-448f-bf18-09f573217053.png">
</p>

2008年後半に行われたIntelとAMDの仕様改訂では、IRIWのケースに「No」を保証し、メモリバリアを強化したが、それでも合理的なハードウェアでは発生し得ないように思える予期せぬ動作を許容している。例えば

<p align="center">
<img width="357" alt="スクリーンショット 2022-09-09 0 47 53" src="https://user-images.githubusercontent.com/55653825/189167222-27be7508-bc90-421c-9bed-7df586c7edd5.png">
</p>

こうした問題を解決するために、Owensらは、以前のSPARCv8のTSOモデルをベースに、x86-TSOモデルを提案した。当時彼らは、"我々の知る限り、x86-TSOは健全で、上でプログラムするのに十分強く、ベンダーの意図に広く沿っている "と主張しました。数ヵ月後、IntelとAMDはこのモデルを大々的に採用した新しいマニュアルを発表した。

Intelがそのことを決定するのに10年かかったとはいえ、すべてのIntelプロセッサは、最初からx86-TSOを実装していたようだ。今にして思えば、IntelとAMDの設計者は、将来のプロセッサの最適化のための余地を残しつつ、コンパイラやアセンブリ言語のプログラマにとって有用な保証をするメモリモデルをどう書くか、まさに頭を悩ませていたのだろう。"As strong as required but no stronger "というのは、バランスをとるのが難しい。

## ARM/POWER Relaxed Memory Model
次に、ARM および POWER プロセッサに見られる、より緩やかなメモリモデルを見てみましょ う。実装レベルでは、この 2 つのシステムは多くの点で異なりますが、保証されたメモリ一貫性モデルはほぼ同様で、x86-TSO や x86-TLO+CC よりもかなり弱いことがわかります。

ARM および POWER システムの概念モデルは、各プロセッサがそれ自身の完全なメモリコピーから読み取り、それ に書き込み、それぞれの書き込みが他のプロセッサに独立して伝搬し、書き込みが伝搬する際に並べ替えが許 されるというものです。

<p align="center">
<img width="351" alt="スクリーンショット 2022-09-09 0 48 41" src="https://user-images.githubusercontent.com/55653825/189167387-b60a1b42-4d71-4e44-b569-ee2e33a6ff9f.png">
</p>

ここでは、総保存順序は存在しない。図には描かれていないが、各プロセッサは、結果が必要になるまで読み出しを延期することも可能で、読み出しを後の書き込みの後まで遅らせることができる。この緩和されたモデルでは、これまで見てきたすべてのリトマス試験に対する答えは、「はい、本当に起こり得ます」です。

元のメッセージパッシングのリトマス試験については、1つのプロセッサによる書き込みの順序を変更することは、スレッド1の書き込みが他のスレッドによって同じ順序で観測されない可能性があることを意味します。

<p align="center">
<img width="342" alt="スクリーンショット 2022-09-09 0 48 49" src="https://user-images.githubusercontent.com/55653825/189167417-cc3209f6-0b24-4586-9bca-c5a424518eb2.png">
</p>


ARM/POWERモデルでは、スレッド1とスレッド2がそれぞれ独立したメモリのコピーを持ち、書き込みがメモリ間で任意の順序で伝搬されると考えることができます。スレッド1のメモリがxの更新を送信する前にyの更新をスレッド2に送信し、その2つの更新の間にスレッド2が実行されると、確かにr1 = 1, r2 = 0という結果が表示されることになります。

この結果は、ARM/POWERのメモリモデルがTSOよりも弱く、ハードウェアに対する要求が少ないことを示しています。ARM/POWERモデルは、TSOが行うような並べ替えをまだ認めている。

<p align="center">
<img width="352" alt="スクリーンショット 2022-09-09 0 48 57" src="https://user-images.githubusercontent.com/55653825/189167447-9ac16579-30b5-4c08-a514-3641aeed99cc.png">
</p>

ARM/POWERでは、xとyへの書き込みはローカルメモリに行われますが、反対側のスレッドで読み取りが発生したときにはまだ伝搬していないかもしれません。

x86がトータルストアオーダーを持つことの意味を示すリトマス試験紙はこちら。

<p align="center">
<img width="395" alt="スクリーンショット 2022-09-09 0 49 08" src="https://user-images.githubusercontent.com/55653825/189167487-f3f6f780-eb85-4fc6-979b-f388e4ba0b36.png">
</p>

ARM/POWERでは、異なるスレッドが異なる順序で異なる書き込みについて学習する可能性があります。そのため、スレッド 3 は x が y よりも先に変更され、スレッド 4 は y が x よりも先に変更されたことを知ることができます。

別の例として、ARM/POWERシステムでは、このリトマス試験で示されるように、メモリリード（ロード）の目に見えるバッファリングまたは並べ替えがあります。

<p align="center">
<img width="338" alt="スクリーンショット 2022-09-09 0 49 36" src="https://user-images.githubusercontent.com/55653825/189167604-b696dbb8-3803-4d22-99eb-953fec97f8c5.png">
</p>

スレッド 1 の r1 = x またはスレッド 2 の r2 = y のどちらかで開始する必要があります。しかし、ARM/POWER メモリモデルでは、プロセッサは命令ストリームの後の書き込みの後まで読み出しを遅らせることができるため、2 つの読み出しの前に y = 1 と x = 1 を実行することができます。

ARMとPOWERの両方のメモリモデルでこの結果が可能ですが、Marangetらは（2012年に）ARMシステムでのみ経験的に再現できたと報告しており、POWERでは全く再現できていません。技術的に保証されているよりも強力なモデルを実装したハードウェアは、強力な動作への依存を助長し、将来的に弱いハードウェアが、有効かどうかにかかわらず、プログラムを破壊することを意味します。

TSO システムのように、ARM と POWER には、上記の例に挿入して順次一貫した動作を強制できるバリアがあります。しかし、障壁のないARM/POWERはいかなる動作も排除するのか、という明白な疑問があります。どのようなリトマス試験でも、「いいえ、それは起こり得ません」という答えが返ってくるのでしょうか。1つのメモリロケーションに注目すれば、それは可能です。

ここで、ARMやPOWERでも起こりえないことについてのリトマス試験紙を見てみましょう。

<p align="center">
<img width="393" alt="スクリーンショット 2022-09-09 0 49 48" src="https://user-images.githubusercontent.com/55653825/189167637-1837ccb3-77e9-414a-96ad-384feb5c2d83.png">
</p>

スレッド 1 とスレッド 2 は相反する値 1 と 2 を x に書き込み、スレッド 3 とスレッド 4 は共に x を 2 回読み取ります。スレッド3がx = 1をx = 2で上書きするのを見た場合、スレッド4はその反対を見ることができるでしょうか？

システム内のスレッドは、1つのメモリ位置への書き込みの合計順序について合意する必要があります。つまり、スレッドはどの書き込みが他の書き込みを上書きするかについて合意していなければならないのです。この性質は、コヒーレンスと呼ばれます。コヒーレンス特性がないと、プロセッサはメモリの最終結果について同意しないか、あるいはメモリ位置がある値から別の値に反転し、最初の値に戻ることを報告する。このようなシステムをプログラムするのは非常に難しい。

ARMとPOWERの弱いメモリモデルでは、多くの微妙な点を意図的に省いています。詳しくは、Peter Sewellの論文のどれかを見てください。また、ARMv8では、メモリモデルを「マルチコピーアトミック」にすることで強化しましたが、その意味を正確に説明するためのスペースはここでは取りません。

重要なポイントは2つあります。1つ目は、非常に粘り強く、非常に賢い人たちが10年以上かけて研究してきたことです。私自身、そのすべてを理解しているわけではありません。これは、普通のプログラマーに説明すべきことではなく、普通のプログラムをデバッグしている間に整理しておきたいことでもないのです。第二に、許容されることと観測されることのギャップが、不幸にも将来の不測の事態を招いてしまうことです。もし現在のハードウェアが許容される動作の全範囲を示さないなら、特に何がそもそも許容されるかを推論するのが難しい場合、必然的に実際のハードウェアの制限の多い動作に偶然依存したプログラムが書かれることになります。もし新しいチップがより制限の少ない動作をするならば、あなたのプログラムを壊す新しい動作が技術的にはハードウェアのメモリモデルで許されているという事実、つまりバグは技術的にはあなたの責任であるという事実は、ほとんど慰めにはならないでしょう。これでは、プログラムを書くどころではありません。

## 弱い順序付けとデータレイスフリーの順序一貫性
ここまでで、ハードウェアの詳細は複雑で微妙なものであり、プログラムを書くたびに作業するようなものではないことを納得していただけたと思います。その代わりに、"もしあなたがこれらの簡単なルールに従うならば、あなたのプログラムはあたかもある順次一貫したインターリーブによってのみ結果を生み出す "という形のショートカットを特定するのに役立つことでしょう。(私たちはまだハードウェアの話をしているので、個々のアセンブリ命令のインターリーブについて話しているのです)。

Sarita AdveとMark Hillは、1990年の論文「Weak Ordering - A New Definition」でまさにこのアプローチを提案しました。彼らは「弱い順序付け」を次のように定義した。

同期モデルを、同期をいつどのように行う必要があるかを指定する、メモリアクセスに関する制約の集合とする。

ハードウェアが同期モデルに対して弱順序であるのは、その同期モデルに従うすべてのソフトウェアに対して順次一貫して見える場合に限られる。

この論文は、当時のハードウェア設計（x86、ARM、POWERではない）を捕らえたものでしたが、特定の設計の上に議論を昇華させるという考え方は、この論文を今日のものに保っています。

私は以前、「有効な最適化は、有効なプログラムの動作を変えることはない」と言いました。ルールが有効な意味を定義し、ハードウェアの最適化によって、シーケンシャルに一貫性のあるマシン上で動作するプログラムを維持しなければならないのです。もちろん、興味深いのはルールそのものであり、プログラムが有効であることの意味を定義する制約である。

AdveとHillは、データ・レース・フリー（DRF）と呼ばれる同期モデルを提案している。このモデルは、ハードウェアが通常のメモリの読み書きとは別にメモリ同期操作を持つことを想定している。通常のメモリリードとライトは、同期操作の間で順番を入れ替えることはできても、同期操作の間を移動することはできない（つまり、同期操作の間に移動することはできない）。(つまり、同期操作は並べ替えの障壁にもなっている）。あるプログラムがデータレースフリーであると言えるのは、理想化されたすべての順次一貫実行において、異なるスレッドから同じ場所への任意の2つの通常のメモリアクセスが、両方とも読み込まれるか、または一方が他方より先に起こることを強制する同期操作によって分離されるかのどちらかであるときです。

AdveとHillの論文からいくつかの例を見てみましょう（プレゼンテーションのために再描画）。ここでは、変数xの書き込みと同じ変数の読み込みを実行するスレッドが1つあります。

<p align="center">
<img width="198" alt="スクリーンショット 2022-09-09 0 52 47" src="https://user-images.githubusercontent.com/55653825/189168331-1cd0a251-4ab7-454c-8561-7b26df5dea37.png">
</p>

垂直の矢印は、単一スレッド内での実行順序を示すもので、書き込みが行われ、次に読み出しが行われる。このプログラムでは、すべてが単一スレッドで行われるため、レースは発生しない。

これに対して、この2スレッドプログラムではレースが発生している。

<p align="center">
<img width="264" alt="スクリーンショット 2022-09-09 0 52 53" src="https://user-images.githubusercontent.com/55653825/189168353-76c7c14c-f6f6-4618-956f-ca6d1f2312eb.png">
</p>

ここでは、スレッド2はスレッド1と協調することなくxに書き込んでいます。スレッド2の書き込みは、スレッド1による書き込みと読み出しの両方と競合する。もし、スレッド2がxを書き込む代わりに読んでいたなら、このプログラムには、スレッド1での書き込みとスレッド2での読み込みの間の1つだけの競合があるはずだ。すべてのレースには少なくとも1つの書き込みが必要であり、調整されていない2つの読み出しは互いにレースにはならない。

レースを避けるためには、同期変数を共有する異なるスレッド上の操作の間に順序を強制する同期操作を追加する必要があります。同期操作S(a)(破線の矢印で示した変数aの同期)によって、スレッド1の書き込みが終わった後にスレッド2の書き込みが行われるようになれば、レースは解消されます。

<p align="center">
<img width="275" alt="スクリーンショット 2022-09-09 0 53 02" src="https://user-images.githubusercontent.com/55653825/189168397-b1f2b8f4-53e3-4ab1-9507-05ab50e568f9.png">
</p>

これで、スレッド2による書き込みは、スレッド1の操作と同時には行えなくなりました。

もしスレッド2が読み込みだけなら、スレッド1の書き込みと同期させるだけでよいのです。2つの読み出しはまだ同時に進行できます。

<p align="center">
<img width="243" alt="スクリーンショット 2022-09-09 0 53 10" src="https://user-images.githubusercontent.com/55653825/189168422-9033b158-0369-4a9a-b8d0-e3fab5fbbdc9.png">
</p>

スレッドは、中間スレッドを使用しても、一連の同期化によって順序付けることができる。このプログラムにはレースがない。

<p align="center">
<img width="343" alt="スクリーンショット 2022-09-09 0 53 44" src="https://user-images.githubusercontent.com/55653825/189168525-44447d77-0476-44f0-bbc1-2be8f822dd1f.png">
</p>

 一方、同期変数を使っても、それだけでレースがなくなるわけではありません。このプログラムにはレースが存在する。

<p align="center">
<img width="333" alt="スクリーンショット 2022-09-09 0 53 55" src="https://user-images.githubusercontent.com/55653825/189168569-793e3cf5-42b8-42c7-a887-b6174957411f.png">
</p>

 スレッド2の読み込みは、他のスレッドの書き込みと適切に同期しています(確かに両方の書き込みの後に発生します)。このプログラムはデータレースフリーではありません。

AdveとHillは弱い順序付けを「ソフトウェアとハードウェアの間の契約」として提示しました。具体的には、ソフトウェアがデータレースを回避すれば、ハードウェアはあたかもシーケンシャルに一貫性があるかのように振る舞う、というもので、前のセクションで検討していたモデルよりも推論しやすくなっています。しかし、ハードウェアはどのようにしてその契約を満たすことができるのでしょうか。

AdveとHillは、ハードウェアが「DRFによって弱く命令される」ことを証明しました。つまり、ある一定の最低要件を満たせば、データレースフリーのプログラムを、あたかも順次一貫した命令によって実行することができるのです。詳細は省きますが、重要なのは、AdveとHillの論文の後、ハードウェア設計者は、証明に裏打ちされたレシピを手に入れたことです。そして実際、ほとんどのゆったりしたハードウェアは、同期操作の適切な実装を前提に、このように動作し、現在も動作し続けています。AdveとHillは元々VAXを対象としていましたが、確かにx86、ARM、POWERもこの制約を満たすことができます。このように、データ・レース・フリーのプログラムに対して、逐次一貫性の外観を保証するシステムは、しばしばDRF-SCと略記される。

DRF-SCは、ハードウェア・メモリ・モデルの転換点となり、ハードウェア設計者とソフトウェア作者（少なくともアセンブリ言語でソフトウェアを書いている人）の双方に明確な戦略を提供することになりました。次回の記事で紹介するように、高級プログラミング言語のメモリモデルの問題は、これほどすっきりとした答えがあるわけではありません。

次回は、プログラミング言語のメモリモデルについてです。
